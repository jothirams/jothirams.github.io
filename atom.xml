<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Thoughts...]]></title>
  <link href="http://www.jothirams.com/atom.xml" rel="self"/>
  <link href="http://www.jothirams.com/"/>
  <updated>2014-11-16T19:18:04+01:00</updated>
  <id>http://www.jothirams.com/</id>
  <author>
    <name><![CDATA[Jothiram Selvam]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Linux Cached Memory]]></title>
    <link href="http://www.jothirams.com/linux-cached-memory/"/>
    <updated>2014-11-15T16:34:25+01:00</updated>
    <id>http://www.jothirams.com/linux-cached-memory</id>
    <content type="html"><![CDATA[<p>We were running a <a href="https://en.wikipedia.org/wiki/Intelligent_Platform_Management_Interface#Baseboard_management_controller">BMC firmware (If you don’t know already, find out what it is?)</a> on top of our custom linux kernel and one fine day we realized that we have developed so many applications that we forgot checking how much memory these applications were using and we were running low on available RAM.</p>

<p>The first thing we saw was, the <code>cached</code> memory in <code>/etc/procmeminfo</code> was too high.</p>

<p>We eventually found what cached was and how we can limit/free it at will. So, lets take a stroll down the memory lane&hellip;</p>

<h2>What is Cached</h2>

<p>In linux there are two things that are part of the of file page cache. The kernel caches</p>

<ul>
<li>The files that your processes access</li>
<li>The RAM based filesystems, such as tmpfs/ramfs, are also part of the cache.</li>
</ul>


<h3>RAM File System Caching</h3>

<p>The <a href="https://www.kernel.org/doc/Documentation/filesystems/tmpfs.txt">kernel tmpfs documentation</a> notes that</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Since tmpfs lives completely in the page cache and on swap, all tmpfs
</span><span class='line'>pages currently in memory will show up as cached. It will not show up
</span><span class='line'>as shared or something like that
</span><span class='line'>
</span><span class='line'>tmpfs has three mount options for sizing:
</span><span class='line'>
</span><span class='line'>size:      The limit of allocated bytes for this tmpfs instance. The 
</span><span class='line'>           default is half of your physical RAM without swap. 
</span><span class='line'>           
</span><span class='line'>           **If you oversize your tmpfs instances the machine will deadlock
</span><span class='line'>           since the OOM handler will not be able to free that memory.**
</span><span class='line'>           
</span><span class='line'>nr_blocks: The same as size, but in blocks of PAGE_CACHE_SIZE.
</span><span class='line'>nr_inodes: The maximum number of inodes for this instance. The default
</span><span class='line'>           is half of the number of your physical RAM pages, or (on a
</span><span class='line'>           machine with highmem) the number of lowmem RAM pages,
</span><span class='line'>           whichever is the lower.</span></code></pre></td></tr></table></div></figure>


<p>To be more clear, any file that you place in your tmpfs will be in the cache forever, till it is deleted. So the downside of tmpfs is, if you oversize the tmpfs eventually the OOM killer will start killing your running processes to get more RAM space, as it cannot free the files in tmpfs from cache unless you have swap (in embedded linux, you don’t have it &ndash; which means you are stuck forever in RAM)</p>

<h3>File Caching</h3>

<p>Anytime a process opens a file, the kernel automatically caches the file there by making subsequent I/O calls to the file faster as it is done in the memory instead of directly on the disk.</p>

<h3>Eviction from the cache</h3>

<p>Kernel automatically reclaims the pagecache when other processes or kernel needs memory. However, if the file is in use then the kernel wouldn’t be able to free the cache. And if the whole system is running short of memory, then the Out-Of-Memory (OOM) killer is called.</p>

<p>After a file is closed, it may still be part of the cache in case the process again tries to open it. But this is in a reclaimable part of the cache, which means if more memory is necessary this closed file will be evicted from the memory.</p>

<p>A file in RAM filesystem will be part of the cache. Uneeded pages will be swapped to swap. If you don’t have swap, then unless you delete the file it is part of cache.</p>

<h2>Best practices for reducing the cache</h2>

<h3>RAM based FileSystem</h3>

<p>When you mount, you can restrict the maximum size of the tmpfs. Note that you cannot limit it using ramfs. Because, <a href="https://www.kernel.org/doc/Documentation/filesystems/tmpfs.txt">as noted in the tmpfs documentation</a></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>If you compare it to ramfs (which was the template to create tmpfs)
</span><span class='line'>you gain swapping and limit checking. Another similar thing is the RAM
</span><span class='line'>disk (/dev/ram*), which simulates a fixed size hard disk in physical
</span><span class='line'>RAM, where you have to create an ordinary filesystem on top. Ramdisks
</span><span class='line'>cannot swap and you do not have the possibility to resize them. </span></code></pre></td></tr></table></div></figure>


<p>So the bottom line is: <em>tmpfs is a better option than ramfs</em>, as you can add swap and also limit the mount size.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># mount -t tmpfs -o size=60M tmpfs /tmp -&gt; Size limited to 60M</span></code></pre></td></tr></table></div></figure>


<h3>Operating on a file</h3>

<p>If you are operating on a file of substantial size, then after the end of the file access you can use <a href="http://linux.die.net/man/2/posix_fadvise">posix_fadvise</a> to evict this file from the cache immediately. This is a much safer option, as you will only evict your file instead of the other files that are being cached.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>#include &lt;fcntl.h&gt;
</span><span class='line'>
</span><span class='line'>int posix_fadvise(int fd, off_t offset, off_t len, int advice);
</span><span class='line'>
</span><span class='line'>If you want to drop the file from cache, the `advice` should be:
</span><span class='line'>  POSIX_FADV_DONTNEED : The specified data will not be accessed in the near future.</span></code></pre></td></tr></table></div></figure>


<h3>Global Drop Cache</h3>

<p>If you want to drop caches of the whole system then write</p>

<pre><code>- `echo 1 &gt; /proc/sys/vm/drop_caches` - Will free pagecache
- `echo 2 &gt; /proc/sys/vm/drop_caches` - Will free dentries and inodes
- `echo 3 &gt; /proc/sys/vm/drop_caches` - Will free pagecache, dentries and inodes
</code></pre>

<h3>Tuning /proc/sys/vm/</h3>

<p>You can control the below values which would help you in freeing up the cache more often.</p>

<ul>
<li><p><strong>/proc/sys/vm/swappiness</strong></p>

<p>  This controls how agressively kernel will swap memory pages out.</p></li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Higher Values = Faster Swapping
</span><span class='line'>Lower Values = Slow to clean up Swap
</span><span class='line'>Value of 0 = Wait to cleanup swap until the high water mark in a zone is reached
</span><span class='line'>Default = 60</span></code></pre></td></tr></table></div></figure>


<ul>
<li><p><strong>/proc/sys/vm/vfs_cache_pressure</strong></p>

<p>  This controls how the kernel will reclaim memory that is used for caching of directory and inode objects. <em>Note: This doesn’t affect the file caching pressure</em></p></li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Higher Value = Faster Cleanup of directory and inode objects  
</span><span class='line'>Lower Value = Slow to clean up directory and inode objects  
</span><span class='line'>Value of 0 = Never clean up directory and inode objects  
</span><span class='line'>Default = 100 (this is a fair rate of cleanup)</span></code></pre></td></tr></table></div></figure>


<ul>
<li><p><strong>/proc/sys/vm/min_free_kbytes</strong></p>

<p>  This forces the VM to keep a minimum number of configured kilobytes free for the atomic operations within the kernel. <em>Note: This is not the free memory that your userspace processes can use.</em></p>

<p>  <code>Choose a value that would be needed by your kernel depending on your kernel configurations</code></p></li>
<li><p><strong>/proc/sys/vm/dirty_background_ratio</strong></p>

<p>  The percentage value of memory that can be filled with dirty pages before pdflush begins to write them.</p>

<p>  <code>If you have huge memory, then the default percentage may be too high. You can lower it</code></p></li>
<li><p><strong>/proc/sys/vm/dirty_expire_centisecs</strong></p>

<p>  The hundreth of the second after which data will be considered to be expired from the page cache and will be written at the next opportunity.</p>

<p>  <code>Reducing will clean up the page cache, but will trigger IO congestion</code></p></li>
<li><p><strong>/proc/sys/vm/dirty_ratio</strong></p>

<p>  The percentage value of memory that can be filled with dirty pages before the processes begin to write them.</p>

<p>  <code>Reducing this will kick in pdflush when a process is writing out huge files. This would block the IO for the process momentarily</code></p></li>
<li><p><strong>/proc/sys/vm/dirty_writeback_centisecs</strong></p>

<p>  The hundredth of a second after which the pdflush wakes up to write data to disk.</p>

<p>  <code>Can reduce the value to avoid data loss, however this will have an effect of IO congestion</code></p></li>
</ul>


<h2>Caching Tools</h2>

<h3>fincore</h3>

<p>This is a nice utility, part of <a href="https://code.google.com/p/linux-ftools/">linux-ftools</a>. You have to give the file name as input, and it will stats for the files that are in the cache now. <em>Hint: Running it on files that are part of tmpfs will show that these files are always in cache</em></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># fincore --pages=false --summarize --only-cached &lt;file_name&gt;</span></code></pre></td></tr></table></div></figure>




<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>fincore [options] files...
</span><span class='line'>
</span><span class='line'>  --pages=false      Do not print pages
</span><span class='line'>  --summarize        When comparing multiple files, print a summary report
</span><span class='line'>  --only-cached      Only print stats for files that are actually in cache.
</span><span class='line'>
</span><span class='line'>root@xxxxxx:/var/lib/mysql/blogindex# fincore --pages=false --summarize --only-cached * 
</span><span class='line'>stats for CLUSTER_LOG_2010_05_21.MYI: file size=93840384 , total pages=22910 , cached pages=1 , cached size=4096, cached perc=0.004365 
</span><span class='line'>stats for CLUSTER_LOG_2010_05_22.MYI: file size=417792 , total pages=102 , cached pages=1 , cached size=4096, cached perc=0.980392 
</span><span class='line'>stats for CLUSTER_LOG_2010_05_23.MYI: file size=826368 , total pages=201 , cached pages=1 , cached size=4096, cached perc=0.497512 
</span><span class='line'>stats for CLUSTER_LOG_2010_05_24.MYI: file size=192512 , total pages=47 , cached pages=1 , cached size=4096, cached perc=2.127660 
</span><span class='line'>stats for CLUSTER_LOG_2010_06_03.MYI: file size=345088 , total pages=84 , cached pages=43 , cached size=176128, cached perc=51.190476 
</span><span class='line'>stats for CLUSTER_LOG_2010_06_04.MYD: file size=1478552 , total pages=360 , cached pages=97 , cached size=397312, cached perc=26.944444 
</span><span class='line'>stats for CLUSTER_LOG_2010_06_04.MYI: file size=205824 , total pages=50 , cached pages=29 , cached size=118784, cached perc=58.000000 
</span><span class='line'>stats for COMMENT_CONTENT_2010_06_03.MYI: file size=100051968 , total pages=24426 , cached pages=10253 , cached size=41996288, cached perc=41.975764 
</span><span class='line'>stats for COMMENT_CONTENT_2010_06_04.MYD: file size=716369644 , total pages=174894 , cached pages=79821 , cached size=326946816, cached perc=45.639645 
</span><span class='line'>stats for COMMENT_CONTENT_2010_06_04.MYI: file size=56832000 , total pages=13875 , cached pages=5365 , cached size=21975040, cached perc=38.666667 
</span><span class='line'>stats for FEED_CONTENT_2010_06_03.MYI: file size=1001518080 , total pages=244511 , cached pages=98975 , cached size=405401600, cached perc=40.478751 
</span><span class='line'>stats for FEED_CONTENT_2010_06_04.MYD: file size=9206385684 , total pages=2247652 , cached pages=1018661 , cached size=4172435456, cached perc=45.321117 
</span><span class='line'>stats for FEED_CONTENT_2010_06_04.MYI: file size=638005248 , total pages=155763 , cached pages=52912 , cached size=216727552, cached perc=33.969556 
</span><span class='line'>stats for FEED_CONTENT_2010_06_04.frm: file size=9840 , total pages=2 , cached pages=3 , cached size=12288, cached perc=150.000000 
</span><span class='line'>stats for PERMALINK_CONTENT_2010_06_03.MYI: file size=1035290624 , total pages=252756 , cached pages=108563 , cached size=444674048, cached perc=42.951700 
</span><span class='line'>stats for PERMALINK_CONTENT_2010_06_04.MYD: file size=55619712720 , total pages=13579031 , cached pages=6590322 , cached size=26993958912, cached perc=48.533080 
</span><span class='line'>stats for PERMALINK_CONTENT_2010_06_04.MYI: file size=659397632 , total pages=160985 , cached pages=54304 , cached size=222429184, cached perc=33.732335 
</span><span class='line'>stats for PERMALINK_CONTENT_2010_06_04.frm: file size=10156 , total pages=2 , cached pages=3 , cached size=12288,</span></code></pre></td></tr></table></div></figure>


<h3>vmtouch</h3>

<p>If you want to modify the files in cache, then you can use <a href="https://github.com/hoytech/vmtouch/blob/master/vmtouch.pod">vmtouch</a>. With vmtouch you can</p>

<ul>
<li>Evict files from cache</li>
<li>Keep a file always in cache, without giving it a possibility to be evicted</li>
</ul>


<h2>Conclusion</h2>

<p>Damn, be extra careful with what you keep in your cache memory. That determines whether you system works as you want it to or not, esp in an embedded linux world.</p>

<p>I will write few more blog entries on how we eventually managed to handle all the memory issues in our firmware.</p>

<p>If you have more tools or thoughts on handling cache better, let me know in the comments.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Anchoring Effect]]></title>
    <link href="http://www.jothirams.com/anchoring-effect/"/>
    <updated>2014-04-28T16:42:15+02:00</updated>
    <id>http://www.jothirams.com/anchoring-effect</id>
    <content type="html"><![CDATA[<p>I&rsquo;m currently reading the book <a href="http://www.amazon.com/Thinking-Fast-Slow-Daniel-Kahneman/dp/0374533555/ref=sr_1_1?ie=UTF8&amp;qid=1398694577&amp;sr=8-1&amp;keywords=thinking+fast+thinking+slow">Thinking Fast and Slow</a> from Daniel Kahneman and I hit upon an interesting fact about Anchoring effect.</p>

<p>So lets first try this with you. Could you answer the following questions:</p>

<blockquote><p>Was Mahatma Gandhi 35 years old when he died? [yes/no]  <br/>
How old was Mahatma Gandhi when he died?</p></blockquote>

<p>Let&rsquo;s try another question:</p>

<blockquote><p>Is Mount Everest 80,000 feet in height? [yes/no]<br/>
What is the height of Mount Everest?</p></blockquote>

<p>Answering these questions before you continue will help you in understanding and realizing this effect better;</p>

<p>Now, after you have answered you can find the correct answers of Mahatma Gandhi&rsquo;s age and Mount Everest&rsquo;s height at the bottom of this post.</p>

<p>If you would have noticed, you might have guessed a little bit higher than 35 years as the age of Mahatma Gandhi when he died, as you might have had a gut feeling that he was not that young during his death. Similarly you would have come up the height of Mount Everest a bit lower than the 80,000 feet that was mentioned in the question earlier, as you might have a intution that 80,000 feet is far too high for a mountain. Please note that, this kind of inference is done only by people who don&rsquo;t know the real answer.</p>

<p>This is what Daniel Kahneman says is <strong>Anchoring Effect</strong>. The point he makes is, once your System 1 (the subconsious brain of yours), picks up a relative answer and when a question is thrown at you for which you don&rsquo;t know the answer then you simply choose the new answer that you derive from the <em>anchor</em> value that your brain had just registered.</p>

<p>This is a very interesting point in understanding (one of the topics of) behavioural economics. This gives you a insight of how you could have been judging and coming to conclusions. You might see this behavior when you are buying goods. Instead of considering it at a face value whether the product price is worthy of its value, you always consider it in comparison with what is already wired in your brain.</p>

<p>From now on, when you arrive at a value or an assumption please first check whether it is due to the <strong>achoring effect</strong> or whether you have reached that because of its significance to the task at hand.</p>

<p>Happy <em>Anchoring</em>!!</p>

<hr />

<p>Mahatma Gandhi was <a href="http://en.wikipedia.org/wiki/Gandhi">78 years old</a> when he died.</p>

<p>Mount Everest is <a href="http://en.wikipedia.org/wiki/Mount_Everest">29,029 ft</a> in height.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Simplicity Over Complexity and Ease]]></title>
    <link href="http://www.jothirams.com/simplicity-over-complexity-and-ease/"/>
    <updated>2014-03-05T17:42:21+01:00</updated>
    <id>http://www.jothirams.com/simplicity-over-complexity-and-ease</id>
    <content type="html"><![CDATA[<h3>Simplicity over Complexity &amp; Ease</h3>

<p>Software development doesn’t have any defined boundaries. Let&rsquo;s take an example from a different field here. If you want to build or manufacture a table, it needs the length, breadth, width, height from the floor, the material in which you want to make it. And all you can do is manipulate the material and the dimensions within these boundaries. While software development also has a boundary, it is not the one that is <strong><em>clearly defined</em></strong>.</p>

<p>One reason why they are this way is because the boundary itself is a user’s perspective of <em>usability</em> which is changes from person to person. There is no right way or one way in programming. Let&rsquo;s consider another example of creating a simple, standard and the world famous “hello world” program, then the defacto standard is to just print hello world. This would be sufficient if you are only going to use this application practically. And for most users of the program that is true. They would just be happy when the program prints hello world.</p>

<p>But we developers are not the users (are we).. The developers and the product marketing engineers will sit together in a conference room and discuss on different ways to print it out. We would think of printing every character of the sentence in a separate line, we will discuss if we have to print the &lsquo;H&rsquo; and &lsquo;W&rsquo; in upper or lower case, should we add a full stop at the end or not and so on and so forth.</p>

<p>Though I’m over exaggerating, sometimes the discussion does go overboard. We tend to over engineer simple things. We miss sometimes the practical usability and concentrate more on theoretically possibilities and decide to code that way. This introduces complexity, which sometimes are not visible for the initial implementor of the code, but will come back and bite the maintainer of the code.</p>

<p>So the approach should be &ndash; always <strong>choose simplicity over complexity</strong> (a point that has been made multiple times by product gurus). I’m just using different words while I still mean the same old <a href="http://simple.wikipedia.org/wiki/KISS_(principle)">KISS Principle</a> &ndash; Keep It Simple Stupid</p>

<h3>Ease of Implementation</h3>

<p>While I recommend simplicity, lets go to the other end of the circle of developers who mistake simplicity to easy of implementation. Sometimes it is easy to print just hello world directly. However, you should think about the possibility to extend the design with minimal changes and how your users will be affected. For instance, if the user runs the program with his name as an argument you should be able to print “hello name” instead. That is extensibility. At the same time, you should print with a new line at the end. Otherwise the user will not be able to identify the print output itself.</p>

<p>So choosing easy of implementation is equally dangerous (the danger lies in the future extensibility), as to choosing complexity (which will waste your precious time now).</p>

<p>Lets revisit the manufacturing shop of the table. I did not mean to say that we cannot introduce the same easy of manufacturing or the complexity in building the same table. We could choose to build a simple and not so comfortable table or we could choose a table with a motor and a sensor that will see how tall the person is and will automatically adjust the height of the table. What I meant to say was, the table manufactures and the users are on the same plane here. The users don’t require such a complexity while the table manufacturers will not spend their time and effort in building a complex one nor will they build a simple one as they have to sell the table in the end.</p>

<p>The goal for me is to build a product that fixes the practical problems without overarching in trying to fix every problem that could eventually occur in the world of probabilities.</p>

<p><strong>Choose simplicity over complexity and ease.</strong></p>
]]></content>
  </entry>
  
</feed>
